<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>æ€§èƒ½ä¼˜åŒ– on Code Whispers</title><link>https://jackypanster.github.io/ai-stream/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link><description>Recent content in æ€§èƒ½ä¼˜åŒ– on Code Whispers</description><generator>Hugo -- 0.148.1</generator><language>zh-cn</language><lastBuildDate>Wed, 09 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://jackypanster.github.io/ai-stream/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>ä»å•å¡ç“¶é¢ˆåˆ°å››å¡é½é£ï¼šä¸€æ¬¡å®Œæ•´çš„Ollamaå¤šGPUæœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–å®æˆ˜</title><link>https://jackypanster.github.io/ai-stream/posts/the-ultimate-guide-to-multi-gpu-ollama-deployment/</link><pubDate>Wed, 09 Jul 2025 00:00:00 +0000</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/the-ultimate-guide-to-multi-gpu-ollama-deployment/</guid><description>è®°å½•å¦‚ä½•å°†ä¸€å°æ‹¥æœ‰4å—RTX 2080 Tiçš„æœåŠ¡å™¨ï¼Œä»æœ€åˆçš„Ollamaå•ç‚¹æœåŠ¡ï¼Œé€æ­¥ä¼˜åŒ–ï¼Œæœ€ç»ˆæ­å»ºæˆä¸€ä¸ªé«˜æ€§èƒ½ã€é«˜å¹¶å‘çš„è´Ÿè½½å‡è¡¡é›†ç¾¤çš„å…¨è¿‡ç¨‹ã€‚</description></item><item><title>DeepSeek-R1-0528-Qwen3-8Béƒ¨ç½²ä¼˜åŒ–å®è·µ</title><link>https://jackypanster.github.io/ai-stream/posts/deploy-deepseek-r1-qwen3-8b-optimization/</link><pubDate>Sat, 07 Jun 2025 17:50:00 +0800</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/deploy-deepseek-r1-qwen3-8b-optimization/</guid><description>&lt;h1 id="deepseek-r1-0528-qwen3-8béƒ¨ç½²ä¼˜åŒ–å®è·µæ€§èƒ½ä¸ç¨³å®šæ€§çš„å¹³è¡¡è‰ºæœ¯">DeepSeek-R1-0528-Qwen3-8Béƒ¨ç½²ä¼˜åŒ–å®è·µï¼šæ€§èƒ½ä¸ç¨³å®šæ€§çš„å¹³è¡¡è‰ºæœ¯&lt;/h1>
&lt;p>åœ¨AIå¤§æ¨¡å‹éƒ¨ç½²é¢†åŸŸï¼Œæœ¬æ–‡è¯¦ç»†è®°å½•å¯¹DeepSeek-R1-0528-Qwen3-8Bæ¨¡å‹ä½¿ç”¨vLLMè¿›è¡Œéƒ¨ç½²ä¼˜åŒ–çš„å…¨è¿‡ç¨‹ï¼Œé‡ç‚¹å…³æ³¨ä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸ç¡¬ä»¶èµ„æºåˆ©ç”¨çš„å¹³è¡¡è°ƒä¼˜ã€‚&lt;/p>
&lt;h2 id="ç¯å¢ƒä¸åŸºç¡€è®¾æ–½">ç¯å¢ƒä¸åŸºç¡€è®¾æ–½&lt;/h2>
&lt;p>æˆ‘ä»¬çš„éƒ¨ç½²ç¯å¢ƒå…·å¤‡ä»¥ä¸‹é…ç½®ï¼š&lt;/p>
&lt;ul>
&lt;li>&lt;strong>GPU&lt;/strong>: 4 x NVIDIA RTX 2080 Tiï¼ˆæ¯å¼ 22GBæ˜¾å­˜ï¼Œæ€»è®¡88GBæ˜¾å­˜ï¼‰
&lt;ul>
&lt;li>æ¶æ„: Turing&lt;/li>
&lt;li>è®¡ç®—èƒ½åŠ›: 7.5&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>CPU&lt;/strong>: 56æ ¸&lt;/li>
&lt;li>&lt;strong>å†…å­˜&lt;/strong>: 512GB RAM&lt;/li>
&lt;li>&lt;strong>å­˜å‚¨&lt;/strong>: 2TB SSD&lt;/li>
&lt;li>&lt;strong>æ“ä½œç³»ç»Ÿ&lt;/strong>: Ubuntu 24.04&lt;/li>
&lt;li>&lt;strong>å®¹å™¨é•œåƒ&lt;/strong>: &lt;code>vllm/vllm-openai:v0.8.5&lt;/code>&lt;/li>
&lt;li>&lt;strong>NVIDIAé©±åŠ¨&lt;/strong>: 570.153.02ï¼ˆCUDA 12.8ï¼‰&lt;/li>
&lt;/ul>
&lt;h2 id="ä¼˜åŒ–å‰çš„éƒ¨ç½²è„šæœ¬åˆ†æ">ä¼˜åŒ–å‰çš„éƒ¨ç½²è„šæœ¬åˆ†æ&lt;/h2>
&lt;p>æˆ‘ä»¬æœ€åˆçš„éƒ¨ç½²è„šæœ¬å¦‚ä¸‹ï¼š&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --gpus all &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name coder &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --shm-size 16g &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ulimit memlock&lt;span style="color:#f92672">=&lt;/span>-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --restart always &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ipc&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /home/llm/model/deepseek/DeepSeek-R1-0528-Qwen3-8B:/models &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 8000:8000 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -e CUDA_MODULE_LOADING&lt;span style="color:#f92672">=&lt;/span>LAZY &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> vllm/vllm-openai:v0.8.5 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --model /models &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --served-model-name coder &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --tensor-parallel-size &lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --gpu-memory-utilization 0.93 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --dtype float16 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --max-model-len &lt;span style="color:#ae81ff">65536&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --trust-remote-code &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --load-format safetensors &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --disable-custom-all-reduce
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>é€šè¿‡åˆ†æï¼Œæˆ‘ä»¬å‘ç°å‡ ä¸ªå¯ä»¥ä¼˜åŒ–çš„å…³é”®ç‚¹ï¼š&lt;/p></description></item><item><title>Qwen3-30B æŠ€æœ¯ä¼˜åŒ–å®è·µï¼ˆäºŒï¼‰ï¼šæ€è€ƒæ¨¡å¼æ§åˆ¶ä¸15-20%æ€§èƒ½æå‡</title><link>https://jackypanster.github.io/ai-stream/posts/deploy-qwen3-part2/</link><pubDate>Wed, 04 Jun 2025 14:30:00 +0800</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/deploy-qwen3-part2/</guid><description>&lt;h1 id="qwen3-30b-æŠ€æœ¯ä¼˜åŒ–å®è·µäºŒæ€è€ƒæ¨¡å¼æ§åˆ¶ä¸æ€§èƒ½æå‡">Qwen3-30B æŠ€æœ¯ä¼˜åŒ–å®è·µï¼ˆäºŒï¼‰ï¼šæ€è€ƒæ¨¡å¼æ§åˆ¶ä¸æ€§èƒ½æå‡&lt;/h1>
&lt;blockquote>
&lt;p>æœ¬æ–‡æ˜¯&lt;a href="blog-post.md">ã€Šä»32Kåˆ°131Kï¼šQwen3-30Bå¤§æ¨¡å‹ä¸Šä¸‹æ–‡æ‰©å±•å®è·µã€‹&lt;/a>çš„ç»­ç¯‡ï¼Œèšç„¦äºæ¨¡å‹æ€§èƒ½è°ƒä¼˜ç‰¹åˆ«æ˜¯æ€è€ƒæ¨¡å¼ï¼ˆreasoning modeï¼‰æ§åˆ¶çš„æŠ€æœ¯ç»†èŠ‚ä¸å®è·µç»éªŒã€‚&lt;/p>&lt;/blockquote>
&lt;p>åœ¨å‰æ–‡ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨YaRNæŠ€æœ¯å°†Qwen3-30Bçš„ä¸Šä¸‹æ–‡é•¿åº¦ä»32Kæ‰©å±•åˆ°131Kã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦ä¸€ä¸ªå…³é”®ä¼˜åŒ–ç»´åº¦ï¼š&lt;strong>æ€è€ƒæ¨¡å¼æ§åˆ¶&lt;/strong>åŠå…¶å¯¹æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡ä¸€ç³»åˆ—å®éªŒå’Œè°ƒä¼˜ï¼Œæˆ‘ä»¬å‘ç°ç¦ç”¨æ€è€ƒæ¨¡å¼å¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹å“åº”é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œç‰¹åˆ«é€‚åˆç¼–ç¨‹å’Œç›´æ¥è¾“å‡ºç±»ä»»åŠ¡åœºæ™¯ã€‚&lt;/p>
&lt;h2 id="-æ€è€ƒæ¨¡å¼reasoning-modeè§£æ">ğŸ” æ€è€ƒæ¨¡å¼ï¼ˆReasoning Modeï¼‰è§£æ&lt;/h2>
&lt;h3 id="ä»€ä¹ˆæ˜¯æ€è€ƒæ¨¡å¼">ä»€ä¹ˆæ˜¯æ€è€ƒæ¨¡å¼ï¼Ÿ&lt;/h3>
&lt;p>æ€è€ƒæ¨¡å¼ï¼ˆReasoning Modeï¼Œä¹Ÿç§°ä¸ºThinking Modeï¼‰æ˜¯Qwen3ç³»åˆ—æ¨¡å‹çš„ä¸€ä¸ªç‰¹æ€§ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸­é—´æ€è€ƒæ­¥éª¤ï¼Œè¿™äº›æ­¥éª¤è¢«åŒ…å«åœ¨&lt;code>&amp;lt;think&amp;gt;...&amp;lt;/think&amp;gt;&lt;/code>æ ‡ç­¾å†…ã€‚ç†è®ºä¸Šï¼Œè¿™ç§&amp;quot;æ€è€ƒè¿‡ç¨‹&amp;quot;æœ‰åŠ©äºæ¨¡å‹è¿›è¡Œæ›´å¤æ‚çš„æ¨ç†ï¼Œä½†åŒæ—¶ä¹Ÿå¼•å…¥äº†é¢å¤–çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ã€‚&lt;/p>
&lt;p>åœ¨é»˜è®¤é…ç½®ä¸‹ï¼ŒQwen3æ¨¡å‹ä¼šå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œäº§ç”Ÿç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;think&amp;gt;
é¦–å…ˆï¼Œæˆ‘éœ€è¦åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼šå¦‚ä½•å®ç°ä¸€ä¸ªç®€å•çš„æ–‡ä»¶è¯»å†™åŠŸèƒ½ã€‚
æˆ‘åº”è¯¥ä½¿ç”¨Pythonçš„å†…ç½®æ–‡ä»¶æ“ä½œåŠŸèƒ½ã€‚
åŸºæœ¬æ­¥éª¤åº”è¯¥æ˜¯ï¼š
1. æ‰“å¼€æ–‡ä»¶ï¼ˆå¯ä»¥ä½¿ç”¨withè¯­å¥è‡ªåŠ¨ç®¡ç†èµ„æºï¼‰
2. è¯»å–æˆ–å†™å…¥å†…å®¹
3. ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
&amp;lt;/think&amp;gt;
ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„Pythonæ–‡ä»¶è¯»å†™ç¤ºä¾‹ï¼š
```python
# å†™å…¥æ–‡ä»¶
with open(&amp;#39;example.txt&amp;#39;, &amp;#39;w&amp;#39;) as file:
file.write(&amp;#39;Hello, World!&amp;#39;)
# è¯»å–æ–‡ä»¶
with open(&amp;#39;example.txt&amp;#39;, &amp;#39;r&amp;#39;) as file:
content = file.read()
print(content)
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>
### æ€è€ƒæ¨¡å¼å®ç°æœºåˆ¶
vLLMéƒ¨ç½²Qwen3æ¨¡å‹æ—¶ï¼Œæ€è€ƒæ¨¡å¼é€šè¿‡ä¸¤ç§æ–¹å¼å®ç°æ§åˆ¶ï¼š
1. **æœåŠ¡å™¨çº§æ§åˆ¶**ï¼šé€šè¿‡éƒ¨ç½²å‚æ•°`--enable-reasoning`å’Œ`--reasoning-parser deepseek_r1`å¯ç”¨
2. **APIçº§æ§åˆ¶**ï¼šé€šè¿‡APIè°ƒç”¨ä¸­çš„`chat_template_kwargs`å‚æ•°æˆ–`enable_thinking`å‚æ•°åŠ¨æ€æ§åˆ¶
æˆ‘ä»¬çš„å‘ç°æ˜¯ï¼Œ**ä»…åˆ é™¤æœåŠ¡å™¨çº§åˆ«çš„å‚æ•°å¹¶ä¸è¶³å¤Ÿå®Œå…¨ç¦ç”¨æ€è€ƒæ¨¡å¼**ï¼Œæ¨¡å‹åœ¨æŸäº›æƒ…å†µä¸‹ä»ä¼šäº§ç”Ÿæ€è€ƒè¿‡ç¨‹ã€‚æ›´å½»åº•çš„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨è‡ªå®šä¹‰èŠå¤©æ¨¡æ¿ã€‚
## ğŸ’¡ ç¦ç”¨æ€è€ƒæ¨¡å¼çš„æŠ€æœ¯å®ç°
### è‡ªå®šä¹‰èŠå¤©æ¨¡æ¿æ–¹æ¡ˆ
ç»è¿‡ç ”ç©¶Qwenå®˜æ–¹æ–‡æ¡£å’Œå®éªŒï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨è‡ªå®šä¹‰èŠå¤©æ¨¡æ¿æ˜¯å®Œå…¨ç¦ç”¨æ€è€ƒæ¨¡å¼çš„æœ€å¯é æ–¹æ³•ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåä¸º`qwen3_nonthinking.jinja`çš„æ¨¡æ¿æ–‡ä»¶ï¼š
```jinja
{% if messages %}
{% set loop_messages = messages %}
{% else %}
{% set loop_messages = [{&amp;#39;role&amp;#39;: &amp;#39;system&amp;#39;, &amp;#39;content&amp;#39;: &amp;#39;&amp;#39;}] %}
{% endif %}
{% for message in loop_messages %}
{% if message[&amp;#39;role&amp;#39;] == &amp;#39;user&amp;#39; %}
&amp;lt;|im_start|&amp;gt;user
{{ message[&amp;#39;content&amp;#39;] }}&amp;lt;|im_end|&amp;gt;
{% elif message[&amp;#39;role&amp;#39;] == &amp;#39;assistant&amp;#39; %}
&amp;lt;|im_start|&amp;gt;assistant
{{ message[&amp;#39;content&amp;#39;] }}&amp;lt;|im_end|&amp;gt;
{% elif message[&amp;#39;role&amp;#39;] == &amp;#39;system&amp;#39; %}
&amp;lt;|im_start|&amp;gt;system
{{ message[&amp;#39;content&amp;#39;] }}&amp;lt;|im_end|&amp;gt;
{% endif %}
{% endfor %}
&amp;lt;|im_start|&amp;gt;assistant
{% if add_generation_prompt is defined and add_generation_prompt %}{{ generation_prompt }}{% endif %}
&lt;/code>&lt;/pre>&lt;p>è¿™ä¸ªæ¨¡æ¿çš„å…³é”®ç‚¹æ˜¯&lt;strong>ç§»é™¤äº†æ‰€æœ‰ä¸æ€è€ƒæ¨¡å¼ç›¸å…³çš„æ ‡ç­¾å’Œå¤„ç†é€»è¾‘&lt;/strong>ï¼Œç¡®ä¿æ¨¡å‹æ— æ³•ç”Ÿæˆ&lt;code>&amp;lt;think&amp;gt;...&amp;lt;/think&amp;gt;&lt;/code>å—ï¼Œå³ä½¿APIè¯·æ±‚ä¸­å°è¯•å¯ç”¨æ€è€ƒæ¨¡å¼ã€‚&lt;/p></description></item></channel></rss>