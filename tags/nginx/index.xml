<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Nginx on Code Whispers</title><link>https://jackypanster.github.io/ai-stream/tags/nginx/</link><description>Recent content in Nginx on Code Whispers</description><generator>Hugo -- 0.148.2</generator><language>zh-cn</language><lastBuildDate>Wed, 09 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://jackypanster.github.io/ai-stream/tags/nginx/index.xml" rel="self" type="application/rss+xml"/><item><title>从单卡瓶颈到四卡齐飞：一次完整的Ollama多GPU服务器性能优化实战</title><link>https://jackypanster.github.io/ai-stream/posts/the-ultimate-guide-to-multi-gpu-ollama-deployment/</link><pubDate>Wed, 09 Jul 2025 00:00:00 +0000</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/the-ultimate-guide-to-multi-gpu-ollama-deployment/</guid><description>记录如何将一台拥有4块RTX 2080 Ti的服务器，从最初的Ollama单点服务，逐步优化，最终搭建成一个高性能、高并发的负载均衡集群的全过程。</description></item></channel></rss>