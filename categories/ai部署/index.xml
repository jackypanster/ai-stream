<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>AIéƒ¨ç½² on Code Whispers</title><link>https://jackypanster.github.io/ai-stream/categories/ai%E9%83%A8%E7%BD%B2/</link><description>Recent content in AIéƒ¨ç½² on Code Whispers</description><generator>Hugo -- 0.148.1</generator><language>zh-cn</language><lastBuildDate>Sat, 07 Jun 2025 17:50:00 +0800</lastBuildDate><atom:link href="https://jackypanster.github.io/ai-stream/categories/ai%E9%83%A8%E7%BD%B2/index.xml" rel="self" type="application/rss+xml"/><item><title>DeepSeek-R1-0528-Qwen3-8Béƒ¨ç½²ä¼˜åŒ–å®è·µ</title><link>https://jackypanster.github.io/ai-stream/posts/deploy-deepseek-r1-qwen3-8b-optimization/</link><pubDate>Sat, 07 Jun 2025 17:50:00 +0800</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/deploy-deepseek-r1-qwen3-8b-optimization/</guid><description>&lt;h1 id="deepseek-r1-0528-qwen3-8béƒ¨ç½²ä¼˜åŒ–å®è·µæ€§èƒ½ä¸ç¨³å®šæ€§çš„å¹³è¡¡è‰ºæœ¯">DeepSeek-R1-0528-Qwen3-8Béƒ¨ç½²ä¼˜åŒ–å®è·µï¼šæ€§èƒ½ä¸ç¨³å®šæ€§çš„å¹³è¡¡è‰ºæœ¯&lt;/h1>
&lt;p>åœ¨AIå¤§æ¨¡å‹éƒ¨ç½²é¢†åŸŸï¼Œæœ¬æ–‡è¯¦ç»†è®°å½•å¯¹DeepSeek-R1-0528-Qwen3-8Bæ¨¡å‹ä½¿ç”¨vLLMè¿›è¡Œéƒ¨ç½²ä¼˜åŒ–çš„å…¨è¿‡ç¨‹ï¼Œé‡ç‚¹å…³æ³¨ä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸ç¡¬ä»¶èµ„æºåˆ©ç”¨çš„å¹³è¡¡è°ƒä¼˜ã€‚&lt;/p>
&lt;h2 id="ç¯å¢ƒä¸åŸºç¡€è®¾æ–½">ç¯å¢ƒä¸åŸºç¡€è®¾æ–½&lt;/h2>
&lt;p>æˆ‘ä»¬çš„éƒ¨ç½²ç¯å¢ƒå…·å¤‡ä»¥ä¸‹é…ç½®ï¼š&lt;/p>
&lt;ul>
&lt;li>&lt;strong>GPU&lt;/strong>: 4 x NVIDIA RTX 2080 Tiï¼ˆæ¯å¼ 22GBæ˜¾å­˜ï¼Œæ€»è®¡88GBæ˜¾å­˜ï¼‰
&lt;ul>
&lt;li>æ¶æ„: Turing&lt;/li>
&lt;li>è®¡ç®—èƒ½åŠ›: 7.5&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>CPU&lt;/strong>: 56æ ¸&lt;/li>
&lt;li>&lt;strong>å†…å­˜&lt;/strong>: 512GB RAM&lt;/li>
&lt;li>&lt;strong>å­˜å‚¨&lt;/strong>: 2TB SSD&lt;/li>
&lt;li>&lt;strong>æ“ä½œç³»ç»Ÿ&lt;/strong>: Ubuntu 24.04&lt;/li>
&lt;li>&lt;strong>å®¹å™¨é•œåƒ&lt;/strong>: &lt;code>vllm/vllm-openai:v0.8.5&lt;/code>&lt;/li>
&lt;li>&lt;strong>NVIDIAé©±åŠ¨&lt;/strong>: 570.153.02ï¼ˆCUDA 12.8ï¼‰&lt;/li>
&lt;/ul>
&lt;h2 id="ä¼˜åŒ–å‰çš„éƒ¨ç½²è„šæœ¬åˆ†æ">ä¼˜åŒ–å‰çš„éƒ¨ç½²è„šæœ¬åˆ†æ&lt;/h2>
&lt;p>æˆ‘ä»¬æœ€åˆçš„éƒ¨ç½²è„šæœ¬å¦‚ä¸‹ï¼š&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --gpus all &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name coder &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --shm-size 16g &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ulimit memlock&lt;span style="color:#f92672">=&lt;/span>-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --restart always &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ipc&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /home/llm/model/deepseek/DeepSeek-R1-0528-Qwen3-8B:/models &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 8000:8000 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -e CUDA_MODULE_LOADING&lt;span style="color:#f92672">=&lt;/span>LAZY &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> vllm/vllm-openai:v0.8.5 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --model /models &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --served-model-name coder &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --tensor-parallel-size &lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --gpu-memory-utilization 0.93 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --dtype float16 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --max-model-len &lt;span style="color:#ae81ff">65536&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --trust-remote-code &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --load-format safetensors &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --disable-custom-all-reduce
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>é€šè¿‡åˆ†æï¼Œæˆ‘ä»¬å‘ç°å‡ ä¸ªå¯ä»¥ä¼˜åŒ–çš„å…³é”®ç‚¹ï¼š&lt;/p></description></item><item><title>Qwen3-30B æŠ€æœ¯ä¼˜åŒ–å®è·µï¼ˆäºŒï¼‰ï¼šæ€è€ƒæ¨¡å¼æ§åˆ¶ä¸15-20%æ€§èƒ½æå‡</title><link>https://jackypanster.github.io/ai-stream/posts/deploy-qwen3-part2/</link><pubDate>Wed, 04 Jun 2025 14:30:00 +0800</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/deploy-qwen3-part2/</guid><description>&lt;h1 id="qwen3-30b-æŠ€æœ¯ä¼˜åŒ–å®è·µäºŒæ€è€ƒæ¨¡å¼æ§åˆ¶ä¸æ€§èƒ½æå‡">Qwen3-30B æŠ€æœ¯ä¼˜åŒ–å®è·µï¼ˆäºŒï¼‰ï¼šæ€è€ƒæ¨¡å¼æ§åˆ¶ä¸æ€§èƒ½æå‡&lt;/h1>
&lt;blockquote>
&lt;p>æœ¬æ–‡æ˜¯&lt;a href="blog-post.md">ã€Šä»32Kåˆ°131Kï¼šQwen3-30Bå¤§æ¨¡å‹ä¸Šä¸‹æ–‡æ‰©å±•å®è·µã€‹&lt;/a>çš„ç»­ç¯‡ï¼Œèšç„¦äºæ¨¡å‹æ€§èƒ½è°ƒä¼˜ç‰¹åˆ«æ˜¯æ€è€ƒæ¨¡å¼ï¼ˆreasoning modeï¼‰æ§åˆ¶çš„æŠ€æœ¯ç»†èŠ‚ä¸å®è·µç»éªŒã€‚&lt;/p>&lt;/blockquote>
&lt;p>åœ¨å‰æ–‡ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨YaRNæŠ€æœ¯å°†Qwen3-30Bçš„ä¸Šä¸‹æ–‡é•¿åº¦ä»32Kæ‰©å±•åˆ°131Kã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦ä¸€ä¸ªå…³é”®ä¼˜åŒ–ç»´åº¦ï¼š&lt;strong>æ€è€ƒæ¨¡å¼æ§åˆ¶&lt;/strong>åŠå…¶å¯¹æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡ä¸€ç³»åˆ—å®éªŒå’Œè°ƒä¼˜ï¼Œæˆ‘ä»¬å‘ç°ç¦ç”¨æ€è€ƒæ¨¡å¼å¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹å“åº”é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œç‰¹åˆ«é€‚åˆç¼–ç¨‹å’Œç›´æ¥è¾“å‡ºç±»ä»»åŠ¡åœºæ™¯ã€‚&lt;/p>
&lt;h2 id="-æ€è€ƒæ¨¡å¼reasoning-modeè§£æ">ğŸ” æ€è€ƒæ¨¡å¼ï¼ˆReasoning Modeï¼‰è§£æ&lt;/h2>
&lt;h3 id="ä»€ä¹ˆæ˜¯æ€è€ƒæ¨¡å¼">ä»€ä¹ˆæ˜¯æ€è€ƒæ¨¡å¼ï¼Ÿ&lt;/h3>
&lt;p>æ€è€ƒæ¨¡å¼ï¼ˆReasoning Modeï¼Œä¹Ÿç§°ä¸ºThinking Modeï¼‰æ˜¯Qwen3ç³»åˆ—æ¨¡å‹çš„ä¸€ä¸ªç‰¹æ€§ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸­é—´æ€è€ƒæ­¥éª¤ï¼Œè¿™äº›æ­¥éª¤è¢«åŒ…å«åœ¨&lt;code>&amp;lt;think&amp;gt;...&amp;lt;/think&amp;gt;&lt;/code>æ ‡ç­¾å†…ã€‚ç†è®ºä¸Šï¼Œè¿™ç§&amp;quot;æ€è€ƒè¿‡ç¨‹&amp;quot;æœ‰åŠ©äºæ¨¡å‹è¿›è¡Œæ›´å¤æ‚çš„æ¨ç†ï¼Œä½†åŒæ—¶ä¹Ÿå¼•å…¥äº†é¢å¤–çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ã€‚&lt;/p>
&lt;p>åœ¨é»˜è®¤é…ç½®ä¸‹ï¼ŒQwen3æ¨¡å‹ä¼šå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œäº§ç”Ÿç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;think&amp;gt;
é¦–å…ˆï¼Œæˆ‘éœ€è¦åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼šå¦‚ä½•å®ç°ä¸€ä¸ªç®€å•çš„æ–‡ä»¶è¯»å†™åŠŸèƒ½ã€‚
æˆ‘åº”è¯¥ä½¿ç”¨Pythonçš„å†…ç½®æ–‡ä»¶æ“ä½œåŠŸèƒ½ã€‚
åŸºæœ¬æ­¥éª¤åº”è¯¥æ˜¯ï¼š
1. æ‰“å¼€æ–‡ä»¶ï¼ˆå¯ä»¥ä½¿ç”¨withè¯­å¥è‡ªåŠ¨ç®¡ç†èµ„æºï¼‰
2. è¯»å–æˆ–å†™å…¥å†…å®¹
3. ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
&amp;lt;/think&amp;gt;
ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„Pythonæ–‡ä»¶è¯»å†™ç¤ºä¾‹ï¼š
```python
# å†™å…¥æ–‡ä»¶
with open(&amp;#39;example.txt&amp;#39;, &amp;#39;w&amp;#39;) as file:
file.write(&amp;#39;Hello, World!&amp;#39;)
# è¯»å–æ–‡ä»¶
with open(&amp;#39;example.txt&amp;#39;, &amp;#39;r&amp;#39;) as file:
content = file.read()
print(content)
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code>
### æ€è€ƒæ¨¡å¼å®ç°æœºåˆ¶
vLLMéƒ¨ç½²Qwen3æ¨¡å‹æ—¶ï¼Œæ€è€ƒæ¨¡å¼é€šè¿‡ä¸¤ç§æ–¹å¼å®ç°æ§åˆ¶ï¼š
1. **æœåŠ¡å™¨çº§æ§åˆ¶**ï¼šé€šè¿‡éƒ¨ç½²å‚æ•°`--enable-reasoning`å’Œ`--reasoning-parser deepseek_r1`å¯ç”¨
2. **APIçº§æ§åˆ¶**ï¼šé€šè¿‡APIè°ƒç”¨ä¸­çš„`chat_template_kwargs`å‚æ•°æˆ–`enable_thinking`å‚æ•°åŠ¨æ€æ§åˆ¶
æˆ‘ä»¬çš„å‘ç°æ˜¯ï¼Œ**ä»…åˆ é™¤æœåŠ¡å™¨çº§åˆ«çš„å‚æ•°å¹¶ä¸è¶³å¤Ÿå®Œå…¨ç¦ç”¨æ€è€ƒæ¨¡å¼**ï¼Œæ¨¡å‹åœ¨æŸäº›æƒ…å†µä¸‹ä»ä¼šäº§ç”Ÿæ€è€ƒè¿‡ç¨‹ã€‚æ›´å½»åº•çš„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨è‡ªå®šä¹‰èŠå¤©æ¨¡æ¿ã€‚
## ğŸ’¡ ç¦ç”¨æ€è€ƒæ¨¡å¼çš„æŠ€æœ¯å®ç°
### è‡ªå®šä¹‰èŠå¤©æ¨¡æ¿æ–¹æ¡ˆ
ç»è¿‡ç ”ç©¶Qwenå®˜æ–¹æ–‡æ¡£å’Œå®éªŒï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨è‡ªå®šä¹‰èŠå¤©æ¨¡æ¿æ˜¯å®Œå…¨ç¦ç”¨æ€è€ƒæ¨¡å¼çš„æœ€å¯é æ–¹æ³•ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåä¸º`qwen3_nonthinking.jinja`çš„æ¨¡æ¿æ–‡ä»¶ï¼š
```jinja
{% if messages %}
{% set loop_messages = messages %}
{% else %}
{% set loop_messages = [{&amp;#39;role&amp;#39;: &amp;#39;system&amp;#39;, &amp;#39;content&amp;#39;: &amp;#39;&amp;#39;}] %}
{% endif %}
{% for message in loop_messages %}
{% if message[&amp;#39;role&amp;#39;] == &amp;#39;user&amp;#39; %}
&amp;lt;|im_start|&amp;gt;user
{{ message[&amp;#39;content&amp;#39;] }}&amp;lt;|im_end|&amp;gt;
{% elif message[&amp;#39;role&amp;#39;] == &amp;#39;assistant&amp;#39; %}
&amp;lt;|im_start|&amp;gt;assistant
{{ message[&amp;#39;content&amp;#39;] }}&amp;lt;|im_end|&amp;gt;
{% elif message[&amp;#39;role&amp;#39;] == &amp;#39;system&amp;#39; %}
&amp;lt;|im_start|&amp;gt;system
{{ message[&amp;#39;content&amp;#39;] }}&amp;lt;|im_end|&amp;gt;
{% endif %}
{% endfor %}
&amp;lt;|im_start|&amp;gt;assistant
{% if add_generation_prompt is defined and add_generation_prompt %}{{ generation_prompt }}{% endif %}
&lt;/code>&lt;/pre>&lt;p>è¿™ä¸ªæ¨¡æ¿çš„å…³é”®ç‚¹æ˜¯&lt;strong>ç§»é™¤äº†æ‰€æœ‰ä¸æ€è€ƒæ¨¡å¼ç›¸å…³çš„æ ‡ç­¾å’Œå¤„ç†é€»è¾‘&lt;/strong>ï¼Œç¡®ä¿æ¨¡å‹æ— æ³•ç”Ÿæˆ&lt;code>&amp;lt;think&amp;gt;...&amp;lt;/think&amp;gt;&lt;/code>å—ï¼Œå³ä½¿APIè¯·æ±‚ä¸­å°è¯•å¯ç”¨æ€è€ƒæ¨¡å¼ã€‚&lt;/p></description></item><item><title>é«˜æ€§èƒ½éƒ¨ç½²Qwen3-30Bï¼švLLMä¼˜åŒ–å®è·µæŒ‡å—</title><link>https://jackypanster.github.io/ai-stream/posts/deploy-qwen3/</link><pubDate>Tue, 03 Jun 2025 16:00:00 +0800</pubDate><guid>https://jackypanster.github.io/ai-stream/posts/deploy-qwen3/</guid><description>&lt;h1 id="é«˜æ€§èƒ½éƒ¨ç½²qwen3-30bvllmä¼˜åŒ–å®è·µæŒ‡å—">é«˜æ€§èƒ½éƒ¨ç½²Qwen3-30Bï¼švLLMä¼˜åŒ–å®è·µæŒ‡å—&lt;/h1>
&lt;h2 id="-æ¦‚è¿°">ğŸ“‹ æ¦‚è¿°&lt;/h2>
&lt;p>æœ¬æ–‡è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨vLLMé«˜æ•ˆéƒ¨ç½²Qwen3-30B-A3Bæ¨¡å‹ï¼Œå®ç°32Kä¸Šä¸‹æ–‡çª—å£å’ŒOpenAIå…¼å®¹APIï¼Œé€‚ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚é€šè¿‡ç²¾ç»†è°ƒæ•´éƒ¨ç½²å‚æ•°ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨æœ‰é™çš„GPUèµ„æºä¸‹æœ€å¤§åŒ–æ¨¡å‹æ€§èƒ½ã€‚&lt;/p>
&lt;h2 id="-ç³»ç»Ÿè¦æ±‚">ğŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>ç¡¬ä»¶é…ç½®&lt;/strong>
&lt;ul>
&lt;li>4å—NVIDIA GPU (æ¯å—22GBæ˜¾å­˜ï¼Œæ€»è®¡88GB)&lt;/li>
&lt;li>512GBç³»ç»Ÿå†…å­˜&lt;/li>
&lt;li>2TB SSDå­˜å‚¨&lt;/li>
&lt;li>56æ ¸CPU&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>è½¯ä»¶ç¯å¢ƒ&lt;/strong>
&lt;ul>
&lt;li>Ubuntu 24.04&lt;/li>
&lt;li>NVIDIAé©±åŠ¨ 550.144.03&lt;/li>
&lt;li>CUDA 12.4&lt;/li>
&lt;li>Docker + NVIDIA Container Toolkit&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="-æ¨¡å‹ä¸æ¶æ„">ğŸ§  æ¨¡å‹ä¸æ¶æ„&lt;/h2>
&lt;p>Qwen3-30B-A3Bæ˜¯é˜¿é‡Œäº‘å‘å¸ƒçš„é€šç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š&lt;/p>
&lt;ul>
&lt;li>30Bå‚æ•°é‡&lt;/li>
&lt;li>åŸç”Ÿæ”¯æŒ32Kä¸Šä¸‹æ–‡é•¿åº¦&lt;/li>
&lt;li>æ”¯æŒæ€è€ƒæ¨¡å¼(Chain-of-Thought)&lt;/li>
&lt;li>ä¼˜å¼‚çš„å¤šè¯­è¨€ä¸ä»£ç èƒ½åŠ›&lt;/li>
&lt;/ul>
&lt;p>æˆ‘ä»¬ä½¿ç”¨vLLMä½œä¸ºæ¨ç†å¼•æ“ï¼Œä¸»è¦åŸºäºä»¥ä¸‹è€ƒé‡ï¼š&lt;/p>
&lt;ol>
&lt;li>&lt;strong>é«˜æ•ˆå†…å­˜ç®¡ç†&lt;/strong>ï¼šé€šè¿‡PagedAttentionæŠ€æœ¯ä¼˜åŒ–KVç¼“å­˜&lt;/li>
&lt;li>&lt;strong>å¼ é‡å¹¶è¡Œ&lt;/strong>ï¼šè‡ªåŠ¨è·¨å¤šGPUåˆ†å¸ƒæ¨¡å‹æƒé‡&lt;/li>
&lt;li>&lt;strong>OpenAIå…¼å®¹API&lt;/strong>ï¼šç›´æ¥æ›¿ä»£OpenAI APIï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰åº”ç”¨&lt;/li>
&lt;li>&lt;strong>åŠ¨æ€æ‰¹å¤„ç†&lt;/strong>ï¼šè‡ªåŠ¨æ‰¹å¤„ç†å¤šè¯·æ±‚ï¼Œæé«˜ååé‡&lt;/li>
&lt;/ol>
&lt;h2 id="-éƒ¨ç½²è„šæœ¬">ğŸ³ éƒ¨ç½²è„šæœ¬&lt;/h2>
&lt;p>ä»¥ä¸‹æ˜¯æˆ‘ä»¬ç”¨äºéƒ¨ç½²çš„Dockerå‘½ä»¤ï¼Œç»è¿‡ç²¾å¿ƒè°ƒä¼˜ä»¥å¹³è¡¡æ€§èƒ½ä¸èµ„æºåˆ©ç”¨ï¼š&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker run -d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --runtime&lt;span style="color:#f92672">=&lt;/span>nvidia &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --gpus&lt;span style="color:#f92672">=&lt;/span>all &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --name coder &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -v /home/llm/model/qwen/qwen3-30b-a3b:/qwen/qwen3-30b-a3b &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -p 8000:8000 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --cpuset-cpus 0-55 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ulimit memlock&lt;span style="color:#f92672">=&lt;/span>-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ulimit stack&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">67108864&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --restart always &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --ipc&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> vllm/vllm-openai:v0.8.5 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --model /qwen/qwen3-30b-a3b &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --served-model-name coder &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --tensor-parallel-size &lt;span style="color:#ae81ff">4&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --dtype half &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --max-model-len &lt;span style="color:#ae81ff">32768&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --max-num-batched-tokens &lt;span style="color:#ae81ff">4096&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --gpu-memory-utilization 0.93 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --block-size &lt;span style="color:#ae81ff">32&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --enable-chunked-prefill &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --swap-space &lt;span style="color:#ae81ff">16&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --tokenizer-pool-size &lt;span style="color:#ae81ff">56&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --disable-custom-all-reduce
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="-å‚æ•°è¯¦è§£ä¸ä¼˜åŒ–ç­–ç•¥">ğŸ”§ å‚æ•°è¯¦è§£ä¸ä¼˜åŒ–ç­–ç•¥&lt;/h2>
&lt;h3 id="dockerå®¹å™¨é…ç½®">Dockerå®¹å™¨é…ç½®&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>å‚æ•°&lt;/th>
&lt;th>å€¼&lt;/th>
&lt;th>ä½œç”¨&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>--runtime=nvidia&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;td>å¯ç”¨NVIDIAå®¹å™¨è¿è¡Œæ—¶&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>--gpus=all&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;td>å°†æ‰€æœ‰GPUæš´éœ²ç»™å®¹å™¨&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>--cpuset-cpus&lt;/code>&lt;/td>
&lt;td>&lt;code>0-55&lt;/code>&lt;/td>
&lt;td>é™åˆ¶å®¹å™¨ä½¿ç”¨0-55å·CPUæ ¸å¿ƒ&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>--ulimit memlock=-1&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;td>ç§»é™¤å†…å­˜é”å®šé™åˆ¶ï¼Œæé«˜æ€§èƒ½&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>--ipc=host&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;td>ä½¿ç”¨ä¸»æœºIPCå‘½åç©ºé—´ï¼Œå¯¹å…±äº«å†…å­˜å¾ˆé‡è¦&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="vllmå¼•æ“é…ç½®">vLLMå¼•æ“é…ç½®&lt;/h3>
&lt;h4 id="1-å¼ é‡å¹¶è¡Œç­–ç•¥">1. å¼ é‡å¹¶è¡Œç­–ç•¥&lt;/h4>
&lt;pre tabindex="0">&lt;code>--tensor-parallel-size 4
&lt;/code>&lt;/pre>&lt;p>æˆ‘ä»¬ä½¿ç”¨4è·¯å¼ é‡å¹¶è¡Œï¼Œå°†æ¨¡å‹åˆ†å¸ƒåœ¨4å—GPUä¸Šã€‚è¿™æ˜¯åŸºäºå®éªŒå¾—å‡ºçš„æœ€ä½³é…ç½® - åœ¨æˆ‘ä»¬çš„ç¡¬ä»¶ä¸Šï¼Œæ¯å—22GBæ˜¾å­˜çš„GPUæ— æ³•å•ç‹¬åŠ è½½å®Œæ•´çš„30Bæ¨¡å‹ã€‚&lt;/p></description></item></channel></rss>